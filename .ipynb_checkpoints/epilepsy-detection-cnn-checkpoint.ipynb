{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules\n",
    "\n",
    "Let's first add these libraries to our project:\n",
    "\n",
    "`numpy`: for matrix operations\n",
    "\n",
    "`tensorlfow`: deep learning layers\n",
    "\n",
    "`maplotlitb`: visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "from tensorflow.python.framework import ops\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for solving the problem\n",
    "\n",
    "<ol>\n",
    "    <li>Read data and format it.</li>\n",
    "    <li>Use sliding window approach to augment data.</li>\n",
    "    <li>Split data into training/dev/test sets.</li>\n",
    "    <li>Create procedure for randomly initializing parameters with specified shape using Xavier's initialization.</li>\n",
    "    <li>Create convolution and pooling procedures.</li>\n",
    "    <li>Implement forward propagation.</li>\n",
    "    <li>Implement cost function.</li>\n",
    "    <li>Create model (uses Adam optimizer for minimization).</li>\n",
    "    <li>Train model.</li>\n",
    "    <li>Hyperparameter tuning using cross-validation sets.</li>\n",
    "    <li>Retrain model until higher accuracy is achevied.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "The sets in the dataset are divided into five categories.\n",
    "\n",
    "\n",
    "SET A:\tZ directory with\tZ000.txt - Z100.txt<br>\n",
    "SET B: \tO directory with\tO000.txt - O100.txt<br>\n",
    "SET C:\tN directory with\tN000.txt - N100.txt<br>\n",
    "SET D:\tF directory\twith\tF000.txt - F100.txt<br>\n",
    "SET E:\tS directory with\tS000.txt - S100.txt<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"dataset/datafile512.h5\"\n",
    "\n",
    "with h5.File(datafile, 'r') as datafile:\n",
    "    X_train = np.array(datafile['X_train'])\n",
    "    Y_train = np.array(datafile['Y_train'])\n",
    "    \n",
    "    X_dev = np.array(datafile['X_dev'])\n",
    "    Y_dev = np.array(datafile['Y_dev'])\n",
    "    \n",
    "    X_test = np.array(datafile['X_test'])\n",
    "    Y_test = np.array(datafile['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dimensions_compatible(arr):\n",
    "    \n",
    "    return arr.reshape(arr.shape[0],-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_dimensions_compatible(X_train)\n",
    "X_dev = make_dimensions_compatible(X_dev)\n",
    "X_test = make_dimensions_compatible(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25650, 512, 1)\n",
      "(25650, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 1000\n",
    "X_dev = X_dev / 1000\n",
    "X_test = X_test / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(parameter_shapes, parameter_values = {}):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow using Xaviar's initialization.\n",
    "    The parameters are:\n",
    "    parameter_shapes: a dictionary where keys represent tensorflow variable names, and values\n",
    "    are shapes of the parameters in a list format\n",
    "    Returns:\n",
    "    params -- a dictionary of tensors containing parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    params = { }\n",
    "    \n",
    "    for n,s in parameter_shapes.items():\n",
    "        param = tf.get_variable(n, s, initializer = tf.contrib.layers.xavier_initializer())\n",
    "        params[n] = param\n",
    "    \n",
    "    for n,v in parameter_values.items():\n",
    "        params[n] = v\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, training=False):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    (CONV BN RELU) -> (CONV BN RELU) -> (CONV BN RELU) -> (FC RELU DROPOUT) -> FC\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters\n",
    "                  \"CONV1_W\", \"CONV2_W\", \"CONV3_W\", \"FC1_units\", \"DO_prob\", \"output_classes\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit (without softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    CONV1_W = parameters['CONV1_W']\n",
    "    CONV1_Str = parameters['CONV1_Str']\n",
    "    CONV2_W = parameters['CONV2_W']\n",
    "    CONV2_Str = parameters['CONV2_Str']\n",
    "    CONV3_W = parameters['CONV3_W']\n",
    "    CONV3_Str = parameters['CONV3_Str']\n",
    "    FC1_units = parameters['FC1_units']\n",
    "    DO_prob = parameters['DO_prob']\n",
    "    output_classes = parameters[\"output_classes\"]\n",
    "    \n",
    "    \n",
    "    #Layer 1\n",
    "    # CONV\n",
    "    Z1 = tf.nn.conv1d(X, CONV1_W, stride=CONV1_Str, padding='VALID', data_format='NWC', name='conv1')\n",
    "    # Batch Normalization\n",
    "    B1 = tf.contrib.layers.batch_norm(Z1, is_training=training)\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(B1)\n",
    "    \n",
    "    #Layer 2\n",
    "    # CONV\n",
    "    Z2 = tf.nn.conv1d(A1, CONV2_W, stride=CONV2_Str, padding='VALID', data_format='NWC', name='conv2')\n",
    "    # Batch Normalization\n",
    "    B2 = tf.contrib.layers.batch_norm(Z2, is_training=training)\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(B2)\n",
    "    \n",
    "    #Layer 3\n",
    "    # CONV\n",
    "    Z3 = tf.nn.conv1d(A2, CONV3_W, stride=CONV3_Str, padding='VALID', data_format='NWC', name='conv3')\n",
    "    # Batch Normalization\n",
    "    B3 = tf.contrib.layers.batch_norm(Z3, is_training=training)\n",
    "    # RELU\n",
    "    A3 = tf.nn.relu(B3)\n",
    "    \n",
    "    # Flatten activations for FC layer\n",
    "    A3_flat = tf.contrib.layers.flatten(A3)\n",
    "    \n",
    "    # Layer 4\n",
    "    # FC\n",
    "    A4 = tf.contrib.layers.fully_connected(A3_flat, FC1_units, activation_fn=tf.nn.relu)\n",
    "    # Dropout\n",
    "    A4_dropped = tf.contrib.layers.dropout(A4, keep_prob=DO_prob, is_training=training)\n",
    "    \n",
    "    # Layer 5\n",
    "    # FC\n",
    "    A5 = tf.contrib.layers.fully_connected(A4_dropped, output_classes, activation_fn=None)\n",
    "    \n",
    "    return A5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv1d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing cost function\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, Y, parameters, training):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply softmax to the output classes and find cross entropy loss\n",
    "    X - Input data\n",
    "    Y - One-hot output class training labels\n",
    "    \n",
    "    Returns:\n",
    "    cost - cross entropy loss\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_hat = forward_propagation(X, parameters, training=True)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Y_hat, labels=Y))\n",
    "    \n",
    "    return cost, Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites for training\n",
    "\n",
    "Here are some procedures that are necessary to execute before the actual training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create placeholders\n",
    "\n",
    "Tensorflow functions take input in the form of `feed_dict`. The variables in other functions are placeholders for the actual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates Tensorflow placeholders that act for input data and their labels\n",
    "    \n",
    "    Arguments:\n",
    "    n_x - no. of features for X\n",
    "    n_x - no. of classes for Y\n",
    "    \n",
    "    Returns:\n",
    "    X - placeholder for data that contains input featurs,\n",
    "        shape: (no. of examples, no. of features). No. of examples is set to None\n",
    "    Y - placeholder for data that contains output class labels,\n",
    "        shape (no. of examples, no. of classes). No. of examples is set ot None\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, name='X', shape=(None, n_x, 1))\n",
    "    Y = tf.placeholder(tf.float32, name='Y', shape=(None, n_y))\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    return X,Y,is_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter shapes\n",
    "\n",
    "To initialize model parameters, we've created a procedure above. It takes as an argument a dictionary in which we supply the model parameter shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_shapes():\n",
    "    \"\"\"\n",
    "    Get tha shapes of all parameters used in the model.\n",
    "    Convolutional layer parameter shapes (filters) are in list format\n",
    "    \n",
    "    Returns:\n",
    "    param_shapes - dict that contains all the parameters as follows\n",
    "    CONV1_W, CONV2_W, CONV3_W\n",
    "    param_values:\n",
    "    CONV1_Str, CONV2_Str, CONV3_Str,\n",
    "    FC1_units, DO_prob, output_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    param_shapes = {}\n",
    "    param_values = {}\n",
    "\n",
    "    # Conv Layer 1 parameter shapes\n",
    "    # No. of channels: 24, Filter size: 5, Stride: 3\n",
    "    param_shapes['CONV1_W'] = [5, 1, 24]\n",
    "    param_values['CONV1_Str'] = 3\n",
    "    \n",
    "    # Conv Layer 2 parameter shapes\n",
    "    # No. of channels: 16, Filter size: 3, Stride: 2\n",
    "    param_shapes['CONV2_W'] = [3, 24, 16]\n",
    "    param_values['CONV2_Str'] = 2\n",
    "    \n",
    "    # Conv Layer 3 parameter shapes\n",
    "    # No. of channels: 8, Filter size: 3, Stride: 2\n",
    "    param_shapes['CONV3_W'] = [3, 16, 8]\n",
    "    param_values['CONV3_Str'] = 2\n",
    "    \n",
    "    # Fully connected layer 1 units = 20\n",
    "    param_values['FC1_units'] = 20\n",
    "    \n",
    "    # Dropout layer after fully connected layer 1 probability\n",
    "    param_values['DO_prob'] = 0.5\n",
    "    \n",
    "    # Fully connected layer 2 units (also last layer)\n",
    "    # No. of units = no. of output classes = 3\n",
    "    param_values['output_classes'] = 3\n",
    "    \n",
    "    return param_shapes, param_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random mini-batches\n",
    "\n",
    "For each epoch we'll use different sets of mini-batches to avoid any possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (number of examples, window size) (m, n_x)\n",
    "    Y -- output classes, of shape (number of examples, output classes) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = np.floor(m/mini_batch_size).astype(int) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "\n",
    "WRITE TEXT HERE...\n",
    "\n",
    "[UPDATE_OPS](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs(costs, dev_costs, learning_rate, total_epochs):\n",
    "    # plot the cost\n",
    "    plt.plot(costs, color='blue', label='training')\n",
    "    plt.plot(dev_costs, color='green', label='dev')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(\"Learning rate = %f\\nTotal Epochs = %i\" % (learning_rate, total_epochs))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True,\n",
    "          save_session_path = None, restore_session = False, save_session_interval=5):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (m, n_x,_) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    dev_costs = []\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y, is_train = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    param_shapes, param_values = parameter_shapes()\n",
    "    parameters = initialize_parameters(param_shapes, param_values)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    # Prediction: Use Y_hat to compute the output class during prediction\n",
    "    cost, Y_hat = compute_cost(X, Y, parameters, is_train)\n",
    "    \n",
    "    # For impementation of batch norm the tf.GraphKeys.UPDATE_OPS dependency needs to be added\n",
    "    # see documentation on tf.contrib.layers.batch_norm\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#     optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # For saving / restoring sesison when training for long\n",
    "    epoch_counter = tf.get_variable('epoch_counter', shape=[], initializer=tf.zeros_initializer)\n",
    "    counter_op = tf.assign_add(epoch_counter, 1)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(Y_hat, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess, tf.control_dependencies(update_ops):\n",
    "        \n",
    "        \n",
    "        # restore the previous session if the path already exists\n",
    "        if (save_session_path != None and restore_session==True):\n",
    "            print(\"Restoring session...\\n\")\n",
    "            saver.restore(sess, save_session_path)\n",
    "            print(\"Previous epoch counter: %i\\n\\n\" % epoch_counter.eval())\n",
    "        else:\n",
    "            sess.run(init)\n",
    "        \n",
    "        print(\"Cost at start: %f\" % cost.eval({X: X_train, Y: Y_train, is_train: False}))\n",
    "        print(\"Dev cost: %f\" % cost.eval({X: X_dev, Y: Y_dev, is_train: False}))\n",
    "        \n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Dev Accuracy:\", dev_accuracy)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    # Select a minibatch\n",
    "                    (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                    # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                    # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                    _,minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y, is_train: True})\n",
    "\n",
    "                    epoch_cost += minibatch_cost / num_minibatches\n",
    "                \n",
    "                # Implement early stopping mechanism on KeyboardInterrupt\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"KeyboardInterrupt received. Stopping early\")\n",
    "                    plot_costs(np.squeeze(costs), np.squeeze(dev_costs), learning_rate, epoch_counter.eval())\n",
    "                    return parameters\n",
    "                \n",
    "\n",
    "            # increment the epoch_counter in case the session is saved\n",
    "            # and restored later\n",
    "            sess.run(counter_op)\n",
    "            \n",
    "            if (epoch % save_session_interval == 0 and save_session_path != None):\n",
    "                saver.save(sess, save_session_path)\n",
    "            \n",
    "            # Save the costs after each epoch for plotting learning curve\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                dev_cost = cost.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "                dev_costs.append(dev_cost)\n",
    "                \n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and (epoch + 1) % 5 == 0:\n",
    "                print (\"\\nCost after epoch %i: %f\" % (epoch + 1, epoch_cost))\n",
    "                print (\"Dev cost after epoch %i: %f\" % (epoch + 1, dev_cost))\n",
    "                \n",
    "                train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "                dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "                print(\"Train Accuracy:\", train_accuracy)\n",
    "                print(\"Dev Accuracy:\", dev_accuracy)\n",
    "                \n",
    "                \n",
    "        if (save_session_path != None):\n",
    "            saver.save(sess, save_session_path)\n",
    "        \n",
    "        \n",
    "        plot_costs(np.squeeze(costs), np.squeeze(dev_costs), learning_rate, epoch_counter.eval())\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Dev Accuracy:\", dev_accuracy)\n",
    "                \n",
    "        return parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring session...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from train/lr-0.00002_mbs-2046_n-512/tf-session.ckpt\n",
      "Previous epoch counter: 812\n",
      "\n",
      "\n",
      "Cost at start: 1.354877\n",
      "Dev cost: 1.350760\n",
      "Train Accuracy: 0.2\n",
      "Dev Accuracy: 0.2\n",
      "\n",
      "Cost after epoch 5: 0.191161\n",
      "Dev cost after epoch 5: 1.353456\n",
      "Train Accuracy: 0.2\n",
      "Dev Accuracy: 0.2\n",
      "KeyboardInterrupt received. Stopping early\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_dev, Y_dev,\n",
    "                   learning_rate=0.00005,\n",
    "                   num_epochs=500,\n",
    "                   minibatch_size=2046,\n",
    "                   save_session_path='train/lr-0.00002_mbs-2046_n-512/tf-session.ckpt',\n",
    "                   restore_session=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>,\n",
       " 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>,\n",
       " 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>,\n",
       " 'CONV1_Str': 3,\n",
       " 'CONV2_Str': 2,\n",
       " 'CONV3_Str': 2,\n",
       " 'FC1_units': 20,\n",
       " 'DO_prob': 0.5,\n",
       " 'output_classes': 3}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'dict'> to Tensor. Contents: {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-0af0a1691af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"parameters-0.00002.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaver_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msave_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1279\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m   1280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1328\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    754\u001b[0m                        \" when eager execution is not enabled.\")\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    661\u001b[0m                            \u001b[0;31m# Avoid comparing ops, sort only by name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                            key=lambda x: x[0]):\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveableObjectsForOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddSaveable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaveables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mSaveableObjectsForOp\u001b[0;34m(op, name)\u001b[0m\n\u001b[1;32m    625\u001b[0m           \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_element\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m           \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IsVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m           raise TypeError(\"names_to_saveables must be a dict mapping string \"\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    215\u001b[0m                                          as_ref=False):\n\u001b[1;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    194\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    523\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    524\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver({\"parameters\": parameters})\n",
    "save_filename = \"parameters-0.00002.ckpt\"\n",
    "with tf.Session() as saver_sess:\n",
    "    save_path = saver.save(saver_sess, \"train/\" + save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 0.1643085 ,  0.02832928,  0.00959623, -0.1577815 ,\n",
      "          0.18924351, -0.01189184, -0.01866665, -0.0223477 ,\n",
      "         -0.08435522,  0.14691184, -0.02915606,  0.11074157,\n",
      "          0.20260207,  0.20071696, -0.1872986 ,  0.12060685,\n",
      "         -0.01182598,  0.12479548,  0.15796684,  0.0713618 ,\n",
      "         -0.09553804,  0.09870629, -0.08830424, -0.02101901]],\n",
      "\n",
      "       [[-0.16887933,  0.16461147, -0.17514198,  0.0358382 ,\n",
      "          0.12785394, -0.0477768 , -0.09394044, -0.06481086,\n",
      "          0.20126636, -0.14165503,  0.09850214,  0.19882835,\n",
      "          0.19975846,  0.03520782, -0.0587478 , -0.07248875,\n",
      "          0.11210789,  0.17382033, -0.17019679, -0.13251658,\n",
      "         -0.05781738,  0.08353408,  0.15923844, -0.03437892]],\n",
      "\n",
      "       [[-0.01887622, -0.00399101, -0.03537577, -0.00912465,\n",
      "         -0.05754562,  0.13235386, -0.21564794, -0.09492114,\n",
      "          0.10254969,  0.11964042, -0.16168648, -0.10999942,\n",
      "          0.05496974,  0.01924798,  0.134133  ,  0.18148993,\n",
      "         -0.05380638,  0.0466698 ,  0.21100672,  0.11605178,\n",
      "         -0.15948132,  0.19808991,  0.03279395, -0.04511204]],\n",
      "\n",
      "       [[-0.1531505 ,  0.1360371 ,  0.17552187, -0.072657  ,\n",
      "          0.10390188,  0.2064978 , -0.2060738 , -0.00251307,\n",
      "          0.10316496,  0.1708117 , -0.18439575,  0.05672057,\n",
      "         -0.07450461,  0.15146177,  0.06291531, -0.15118815,\n",
      "         -0.01062907, -0.0947226 ,  0.00894162, -0.19388433,\n",
      "         -0.10948235, -0.01592223,  0.17893966, -0.02725476]],\n",
      "\n",
      "       [[-0.04409654,  0.1685492 , -0.11375062, -0.09052035,\n",
      "          0.14411877, -0.11179066, -0.04502575, -0.17790776,\n",
      "         -0.17113179,  0.16160111,  0.01867341, -0.10262924,\n",
      "         -0.18486305, -0.11137895,  0.20629053,  0.10506319,\n",
      "          0.04275133, -0.04294497, -0.1365886 , -0.08690064,\n",
      "         -0.05178347,  0.10505648,  0.09812795,  0.12511526]]],\n",
      "      dtype=float32), array([[[ 0.03454825, -0.07327656, -0.18433392, ...,  0.01384151,\n",
      "         -0.0376384 , -0.21241197],\n",
      "        [ 0.0264369 ,  0.09737429, -0.1662314 , ...,  0.01771265,\n",
      "          0.02779716,  0.2148824 ],\n",
      "        [ 0.09074643,  0.14955875,  0.10030431, ..., -0.17436606,\n",
      "          0.1132088 , -0.19364998],\n",
      "        ...,\n",
      "        [ 0.13966292,  0.09236509, -0.02404495, ..., -0.06317516,\n",
      "         -0.04378319,  0.17765734],\n",
      "        [-0.19157821,  0.15578228,  0.0189836 , ...,  0.0289264 ,\n",
      "         -0.11181726,  0.15346962],\n",
      "        [-0.15033194, -0.13815138, -0.06678775, ...,  0.20982501,\n",
      "         -0.08370359, -0.00093867]],\n",
      "\n",
      "       [[ 0.19088665, -0.02133679,  0.14586759, ...,  0.05037734,\n",
      "         -0.00991294,  0.19605312],\n",
      "        [ 0.04065531, -0.17088324, -0.00174026, ..., -0.14537781,\n",
      "          0.19790578,  0.12841159],\n",
      "        [ 0.03534409,  0.14828753,  0.08637324, ...,  0.1203579 ,\n",
      "         -0.02153736, -0.14773005],\n",
      "        ...,\n",
      "        [ 0.20435509,  0.12785128,  0.17734796, ...,  0.14683509,\n",
      "          0.07817471,  0.12274739],\n",
      "        [ 0.19478527, -0.08566473, -0.08895856, ..., -0.00590713,\n",
      "          0.05258766,  0.07641312],\n",
      "        [ 0.1245679 , -0.06362133,  0.01101671, ...,  0.08452523,\n",
      "          0.20335132,  0.0348587 ]],\n",
      "\n",
      "       [[-0.09215297,  0.00598225, -0.08681248, ..., -0.18807061,\n",
      "          0.10308492,  0.14881563],\n",
      "        [ 0.05426043,  0.05483988,  0.01513442, ...,  0.15597942,\n",
      "          0.18479496,  0.01043727],\n",
      "        [ 0.21021515, -0.07014853, -0.01030777, ...,  0.03580993,\n",
      "          0.13476515, -0.11279953],\n",
      "        ...,\n",
      "        [ 0.10904738, -0.04719312,  0.16810265, ...,  0.19397241,\n",
      "         -0.05813323, -0.21560493],\n",
      "        [ 0.12123638,  0.13133243, -0.05182946, ..., -0.02149242,\n",
      "         -0.16068082,  0.20637628],\n",
      "        [ 0.04394537, -0.11068022, -0.10675342, ..., -0.11137413,\n",
      "         -0.06647837,  0.01350191]]], dtype=float32), array([[[ 1.02950722e-01,  1.18730545e-01,  1.07318997e-01,\n",
      "         -8.23232234e-02,  7.22426176e-02,  2.65023172e-01,\n",
      "          6.90088570e-02, -2.83344179e-01],\n",
      "        [-2.46273652e-01,  1.98538214e-01,  2.46038437e-01,\n",
      "         -1.82627946e-01, -1.52395800e-01, -2.63979852e-01,\n",
      "         -2.27670670e-02, -1.25692457e-01],\n",
      "        [-3.07884812e-02, -3.99737954e-02, -5.51048666e-02,\n",
      "          6.06123507e-02, -2.14976013e-01, -2.05507413e-01,\n",
      "          5.10406494e-02, -9.43745077e-02],\n",
      "        [-2.23446503e-01, -1.58778533e-01,  3.96336615e-02,\n",
      "         -1.51973620e-01, -1.27636433e-01, -1.76890522e-01,\n",
      "         -2.90343761e-02,  2.11624682e-01],\n",
      "        [ 3.37957442e-02,  8.81038904e-02,  9.72135067e-02,\n",
      "         -5.28866202e-02, -9.40107703e-02,  1.39111698e-01,\n",
      "         -1.26710251e-01,  2.06310600e-01],\n",
      "        [-9.03185457e-02,  1.20239079e-01,  2.70825744e-01,\n",
      "          6.90641999e-02, -1.40377343e-01,  1.94017887e-01,\n",
      "          7.76210725e-02,  1.92006946e-01],\n",
      "        [ 2.60322213e-01, -1.86103567e-01, -4.73356396e-02,\n",
      "          1.31012946e-01,  5.36055863e-02, -1.49103254e-01,\n",
      "          9.57444906e-02,  2.63774395e-02],\n",
      "        [ 9.58490372e-03,  5.87722957e-02,  1.55969977e-01,\n",
      "          1.74715161e-01,  1.10131979e-01, -1.79722965e-01,\n",
      "         -2.02977732e-01, -8.39007050e-02],\n",
      "        [ 9.20522809e-02,  2.81835616e-01, -7.94733018e-02,\n",
      "          1.23090357e-01,  2.76783705e-01,  1.58143133e-01,\n",
      "          2.03613669e-01, -1.57769322e-02],\n",
      "        [ 2.83651412e-01,  2.36370862e-02,  1.26903713e-01,\n",
      "         -7.21476525e-02,  2.10845917e-01, -2.62569487e-01,\n",
      "          2.28163481e-01,  3.40013802e-02],\n",
      "        [-1.71139389e-01, -2.72915065e-02,  6.28378987e-02,\n",
      "         -1.44607767e-01,  1.30800962e-01, -1.05573595e-01,\n",
      "          8.13111663e-03, -2.88549602e-01],\n",
      "        [ 7.62977600e-02,  1.03350192e-01, -2.10062087e-01,\n",
      "         -3.14284861e-02, -6.53753579e-02,  2.84851491e-02,\n",
      "          2.82338381e-01,  7.89079070e-02],\n",
      "        [ 1.15689635e-03, -2.51100361e-02,  2.55950332e-01,\n",
      "         -4.99835014e-02, -1.34336799e-01,  1.70196891e-01,\n",
      "         -2.52049506e-01,  2.71742284e-01],\n",
      "        [-1.89778984e-01, -2.40322724e-01,  2.45203614e-01,\n",
      "          2.04512477e-01, -1.79761365e-01,  1.92244381e-01,\n",
      "          1.49027675e-01, -1.68645769e-01],\n",
      "        [ 1.34132117e-01, -7.20069110e-02,  2.34913051e-01,\n",
      "         -1.96531266e-01,  1.61745042e-01, -1.94820046e-01,\n",
      "         -2.87820458e-01, -1.67443871e-01],\n",
      "        [ 6.68334961e-02,  7.14491308e-02,  9.42706466e-02,\n",
      "         -1.34689599e-01, -1.26563907e-02,  1.37816548e-01,\n",
      "          1.63856953e-01, -2.61959344e-01]],\n",
      "\n",
      "       [[ 2.17077672e-01,  1.87536240e-01,  5.84517121e-02,\n",
      "         -2.43552357e-01,  2.30777860e-01,  9.85579193e-02,\n",
      "         -1.34772271e-01,  4.11887765e-02],\n",
      "        [ 2.51484394e-01,  1.86256856e-01, -1.41883999e-01,\n",
      "          1.99499488e-01,  2.79091716e-01, -1.80168197e-01,\n",
      "          5.14957309e-02,  4.73426580e-02],\n",
      "        [-2.05032229e-01,  9.48527753e-02,  2.10830569e-02,\n",
      "         -1.31457359e-01, -5.30168414e-02, -6.81270659e-02,\n",
      "         -9.00667906e-02, -1.09920129e-01],\n",
      "        [ 9.95755792e-02, -9.47534591e-02, -1.63414761e-01,\n",
      "          8.57711136e-02,  1.30634397e-01,  1.21790111e-01,\n",
      "          2.78981864e-01, -1.73031539e-01],\n",
      "        [-8.05658400e-02,  1.26271486e-01,  2.20297575e-01,\n",
      "          1.56350374e-01, -1.73342705e-01,  1.50721192e-01,\n",
      "          2.54926443e-01, -2.31285319e-01],\n",
      "        [-5.49211055e-02,  9.10106301e-03,  4.38214242e-02,\n",
      "         -1.10613406e-01,  4.25764918e-02,  2.07217723e-01,\n",
      "          2.76342630e-02, -5.85610867e-02],\n",
      "        [-2.42733061e-02, -2.42362648e-01,  1.22362822e-01,\n",
      "          3.44445407e-02, -2.81431586e-01,  1.96363539e-01,\n",
      "          1.10555053e-01,  6.84531629e-02],\n",
      "        [ 1.63581878e-01,  2.07843691e-01,  9.27260816e-02,\n",
      "          5.88607490e-02, -1.15785301e-02, -2.88280547e-01,\n",
      "         -2.89491713e-02, -1.78664923e-04],\n",
      "        [ 1.41320199e-01, -1.34216428e-01, -4.75118309e-02,\n",
      "         -1.08882859e-01, -8.35332572e-02,  3.06995511e-02,\n",
      "          9.61816013e-02,  2.74289191e-01],\n",
      "        [-7.31465220e-03, -2.42105514e-01, -5.83755970e-03,\n",
      "          1.29757524e-02,  6.21838570e-02, -1.81705967e-01,\n",
      "         -3.61042917e-02,  2.52677202e-01],\n",
      "        [ 4.78157401e-03,  2.73520827e-01, -3.65942717e-04,\n",
      "          2.75783360e-01,  1.60678655e-01,  2.00209141e-01,\n",
      "         -9.93467420e-02,  5.61647713e-02],\n",
      "        [ 2.44768381e-01, -7.13432878e-02, -1.99440375e-01,\n",
      "         -8.72054696e-03, -5.34320623e-02, -2.78233290e-02,\n",
      "         -3.43827605e-02,  2.66410947e-01],\n",
      "        [-2.09450692e-01,  2.73653150e-01, -6.39496446e-02,\n",
      "         -8.29343945e-02,  1.84497237e-02,  8.89908969e-02,\n",
      "         -4.20951992e-02,  6.57205284e-02],\n",
      "        [ 1.27949923e-01, -1.61904514e-01,  1.06198609e-01,\n",
      "         -9.87475514e-02, -2.32993156e-01,  9.74774361e-02,\n",
      "         -2.19867304e-01, -1.29379854e-01],\n",
      "        [ 2.37938762e-02,  2.34745800e-01,  1.10285521e-01,\n",
      "         -2.70861149e-01, -2.83558518e-01, -1.96012110e-01,\n",
      "         -8.67789984e-02, -2.69347131e-02],\n",
      "        [-2.64090300e-01, -2.61319041e-01,  1.12095773e-01,\n",
      "          1.16068870e-01,  4.22601700e-02,  2.73968041e-01,\n",
      "         -4.94633764e-02, -2.16769055e-01]],\n",
      "\n",
      "       [[ 1.72984064e-01,  4.06078100e-02, -2.84014463e-01,\n",
      "         -2.15610594e-01, -2.66804099e-02,  2.12236464e-01,\n",
      "          2.35042572e-01,  9.04244184e-03],\n",
      "        [ 2.54772961e-01,  1.31989360e-01, -1.47773057e-01,\n",
      "          2.10858256e-01,  1.32705301e-01,  2.31767893e-02,\n",
      "          9.35549438e-02, -1.25227064e-01],\n",
      "        [-1.14757717e-02,  2.29272425e-01, -1.97507545e-01,\n",
      "         -2.74226576e-01,  1.32009953e-01, -1.23115152e-01,\n",
      "          1.67219907e-01,  2.51698434e-01],\n",
      "        [ 2.76752472e-01,  3.91109288e-02, -1.66488290e-02,\n",
      "          1.40302807e-01, -1.02879271e-01,  2.55242646e-01,\n",
      "         -1.76653415e-01, -5.16962856e-02],\n",
      "        [-7.53324181e-02, -3.12095881e-03,  2.09848374e-01,\n",
      "         -1.00263909e-01,  2.10619867e-02, -8.64804238e-02,\n",
      "         -9.16178375e-02,  7.63621032e-02],\n",
      "        [-3.80457938e-02, -2.65606046e-02,  5.98763525e-02,\n",
      "         -2.15495855e-01, -1.14389926e-01, -1.65411651e-01,\n",
      "          1.17951781e-01, -7.62358159e-02],\n",
      "        [ 1.41508698e-01, -2.31706798e-01, -1.71919167e-02,\n",
      "         -2.72764951e-01, -2.17244923e-01,  2.65020907e-01,\n",
      "          1.50473624e-01, -2.48908103e-02],\n",
      "        [ 7.66454637e-02, -1.13805190e-01,  2.72380292e-01,\n",
      "          1.82288170e-01, -3.45466137e-02, -1.99644864e-02,\n",
      "          7.46965408e-02,  1.13599598e-01],\n",
      "        [-2.87346184e-01,  1.38681561e-01, -1.76061869e-01,\n",
      "          6.47832453e-02, -1.17661282e-01, -1.52566269e-01,\n",
      "          3.70444357e-02,  1.03836298e-01],\n",
      "        [ 1.92352116e-01, -3.70763838e-02, -1.04354352e-01,\n",
      "          1.13566160e-01,  1.17064297e-01, -1.03444204e-01,\n",
      "          1.95107818e-01,  3.01044285e-02],\n",
      "        [-1.92425668e-01, -1.18113533e-01,  2.69835711e-01,\n",
      "          1.52462333e-01,  1.79591924e-01, -1.90701321e-01,\n",
      "         -2.15742856e-01,  1.75316900e-01],\n",
      "        [ 2.52963781e-01, -4.10325974e-02,  5.41266501e-02,\n",
      "          2.33979821e-01, -2.72689849e-01, -2.64694333e-01,\n",
      "         -1.47999018e-01,  3.24014127e-02],\n",
      "        [-8.56428891e-02,  2.21977651e-01,  7.31682777e-02,\n",
      "         -1.12265363e-01,  2.92432606e-02, -7.43502825e-02,\n",
      "         -1.02957532e-01, -1.59043863e-01],\n",
      "        [ 7.78135061e-02,  2.10855901e-02,  3.23891640e-03,\n",
      "         -2.91174650e-03,  2.83964038e-01,  2.64204383e-01,\n",
      "         -2.17408240e-02,  1.18493915e-01],\n",
      "        [-5.22500575e-02, -5.08023202e-02,  9.91666913e-02,\n",
      "          2.54862368e-01, -1.21082246e-01,  2.49309182e-01,\n",
      "         -2.51968831e-01,  2.13175237e-01],\n",
      "        [-3.27252150e-02,  2.44670153e-01,  2.23190606e-01,\n",
      "          2.18800962e-01,  2.16511488e-01,  1.55409276e-02,\n",
      "          5.58165908e-02, -1.93617180e-01]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 0.0938587 , -0.07239331, -0.06818514, ...,  0.02098723,\n",
      "         0.04155301,  0.05539155],\n",
      "       [-0.01821527, -0.08697401, -0.11177664, ..., -0.10056333,\n",
      "         0.082904  , -0.02161622],\n",
      "       [-0.11454282,  0.11155944, -0.12167596, ...,  0.01112506,\n",
      "         0.00296307, -0.0262356 ],\n",
      "       ...,\n",
      "       [-0.00430894,  0.0572931 , -0.09514384, ..., -0.06464636,\n",
      "         0.1161419 ,  0.04919173],\n",
      "       [ 0.1122954 , -0.00684194, -0.02432487, ..., -0.08732492,\n",
      "         0.10387705,  0.04345487],\n",
      "       [-0.08378898, -0.01144139, -0.05281067, ..., -0.11202651,\n",
      "        -0.0297015 , -0.08832225]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), array([[ 0.17008138, -0.29384038, -0.17582312],\n",
      "       [ 0.00385129,  0.23175842, -0.04472902],\n",
      "       [-0.21134475, -0.20951521,  0.00133795],\n",
      "       [ 0.16000634, -0.32329294, -0.09981862],\n",
      "       [ 0.23417515,  0.48110473,  0.27441633],\n",
      "       [ 0.30358166, -0.34617826, -0.04411149],\n",
      "       [-0.19648099,  0.03667688,  0.02367514],\n",
      "       [ 0.22302496,  0.2957548 ,  0.42723453],\n",
      "       [-0.00428814, -0.4516687 ,  0.39783603],\n",
      "       [ 0.22385854,  0.01701647,  0.18520135],\n",
      "       [ 0.11497879, -0.44391164,  0.27624393],\n",
      "       [-0.04469064, -0.16853267, -0.25371757],\n",
      "       [-0.3041938 ,  0.30201828, -0.22988763],\n",
      "       [ 0.48649782,  0.43864554,  0.4829765 ],\n",
      "       [ 0.2568043 ,  0.28930557,  0.15248835],\n",
      "       [ 0.03378099,  0.03613704,  0.38515252],\n",
      "       [ 0.23071128,  0.06223392,  0.36065465],\n",
      "       [-0.11145878, -0.19355574,  0.4271729 ],\n",
      "       [ 0.22493279,  0.20551085,  0.19637382],\n",
      "       [ 0.3531229 , -0.3203163 , -0.5090971 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 3.95124257e-02, -1.14047468e-01,  9.16563272e-02, ...,\n",
      "         9.97388959e-02,  1.15336046e-01,  4.57376689e-02],\n",
      "       [-4.13841084e-02, -8.42704922e-02, -6.64013997e-02, ...,\n",
      "        -7.04465285e-02,  8.28883052e-02, -5.17144799e-04],\n",
      "       [-7.39231706e-02, -1.72678009e-02, -3.12894583e-02, ...,\n",
      "         1.40619874e-02,  8.43380392e-03, -9.59861577e-02],\n",
      "       ...,\n",
      "       [ 9.15815383e-02, -8.19035172e-02, -9.41449031e-02, ...,\n",
      "         2.42517740e-02,  1.03577465e-01,  2.04876661e-02],\n",
      "       [-7.72297010e-02, -1.04477726e-01,  3.24738175e-02, ...,\n",
      "        -5.34086078e-02,  3.88605893e-03,  1.00998834e-01],\n",
      "       [-3.24654952e-02,  3.49085480e-02, -1.13127008e-01, ...,\n",
      "         1.20908409e-01, -1.07735395e-05,  9.57140177e-02]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), array([[-0.29862058, -0.44624907,  0.21366   ],\n",
      "       [ 0.26665425,  0.13070041,  0.20315486],\n",
      "       [-0.37168783,  0.02024859,  0.44429207],\n",
      "       [-0.39684933,  0.2000565 , -0.17609468],\n",
      "       [-0.05052942,  0.47739136, -0.2529828 ],\n",
      "       [-0.03275603,  0.28452605,  0.37867087],\n",
      "       [ 0.48413622, -0.2487379 ,  0.2599476 ],\n",
      "       [ 0.08251607,  0.26540947,  0.503105  ],\n",
      "       [-0.08899528,  0.47121477,  0.02866066],\n",
      "       [-0.07428119, -0.4686378 ,  0.40427893],\n",
      "       [-0.03408322,  0.5034773 , -0.46455207],\n",
      "       [ 0.46196437,  0.5001771 ,  0.14000452],\n",
      "       [ 0.2928999 ,  0.35588312,  0.24679661],\n",
      "       [ 0.33063585, -0.44646436,  0.15195471],\n",
      "       [-0.06311822,  0.04519856, -0.0905686 ],\n",
      "       [-0.08188018,  0.47788906, -0.28416136],\n",
      "       [-0.18828857, -0.30228755, -0.06532854],\n",
      "       [ 0.15629607,  0.4906674 , -0.3866003 ],\n",
      "       [ 0.08491296,  0.15673262,  0.27497488],\n",
      "       [-0.32988864,  0.46208346, -0.08739921]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(train_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
