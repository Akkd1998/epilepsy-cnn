{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules\n",
    "\n",
    "Let's first add these libraries to our project:\n",
    "\n",
    "`numpy`: for matrix operations\n",
    "\n",
    "`tensorlfow`: deep learning layers\n",
    "\n",
    "`maplotlitb`: visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for solving the problem\n",
    "\n",
    "<ol>\n",
    "    <li>Read data and format it.</li>\n",
    "    <li>Use sliding window approach to augment data.</li>\n",
    "    <li>Split data into training/dev/test sets.</li>\n",
    "    <li>Create procedure for randomly initializing parameters with specified shape using Xavier's initialization.</li>\n",
    "    <li>Create convolution and pooling procedures.</li>\n",
    "    <li>Implement forward propagation.</li>\n",
    "    <li>Implement cost function.</li>\n",
    "    <li>Create model (uses Adam optimizer for minimization).</li>\n",
    "    <li>Train model.</li>\n",
    "    <li>Hyperparameter tuning using cross-validation sets.</li>\n",
    "    <li>Retrain model until higher accuracy is achevied.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "The sets in the dataset are divided into five categories.\n",
    "\n",
    "\n",
    "SET A:\tZ directory with\tZ000.txt - Z100.txt<br>\n",
    "SET B: \tO directory with\tO000.txt - O100.txt<br>\n",
    "SET C:\tN directory with\tN000.txt - N100.txt<br>\n",
    "SET D:\tF directory\twith\tF000.txt - F100.txt<br>\n",
    "SET E:\tS directory with\tS000.txt - S100.txt<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"dataset/datafile512.h5\"\n",
    "\n",
    "with h5.File(datafile, 'r') as datafile:\n",
    "    X_train = np.array(datafile['X_train'])\n",
    "    Y_train = np.array(datafile['Y_train'])\n",
    "    \n",
    "    X_dev = np.array(datafile['X_dev'])\n",
    "    Y_dev = np.array(datafile['Y_dev'])\n",
    "    \n",
    "    X_test = np.array(datafile['X_test'])\n",
    "    Y_test = np.array(datafile['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dimensions_compatible(arr):\n",
    "    \n",
    "    return arr.reshape(arr.shape[0],-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = make_dimensions_compatible(X_train)\n",
    "X_dev = make_dimensions_compatible(X_dev)\n",
    "X_test = make_dimensions_compatible(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25650, 512, 1)\n",
      "(25650, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 1000\n",
    "X_dev = X_dev / 1000\n",
    "X_test = X_test / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(parameter_shapes, parameter_values = {}):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow using Xaviar's initialization.\n",
    "    The parameters are:\n",
    "    parameter_shapes: a dictionary where keys represent tensorflow variable names, and values\n",
    "    are shapes of the parameters in a list format\n",
    "    Returns:\n",
    "    params -- a dictionary of tensors containing parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    params = { }\n",
    "    \n",
    "    for n,s in parameter_shapes.items():\n",
    "        param = tf.get_variable(n, s, initializer = tf.contrib.layers.xavier_initializer())\n",
    "        params[n] = param\n",
    "    \n",
    "    for n,v in parameter_values.items():\n",
    "        params[n] = v\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, training=False):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    (CONV BN RELU) -> (CONV BN RELU) -> (CONV BN RELU) -> (FC RELU DROPOUT) -> FC\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters\n",
    "                  \"CONV1_W\", \"CONV2_W\", \"CONV3_W\", \"FC1_units\", \"DO_prob\", \"output_classes\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit (without softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    CONV1_W = parameters['CONV1_W']\n",
    "    CONV1_Str = parameters['CONV1_Str']\n",
    "    CONV2_W = parameters['CONV2_W']\n",
    "    CONV2_Str = parameters['CONV2_Str']\n",
    "    CONV3_W = parameters['CONV3_W']\n",
    "    CONV3_Str = parameters['CONV3_Str']\n",
    "    FC1_units = parameters['FC1_units']\n",
    "    DO_prob = parameters['DO_prob']\n",
    "    output_classes = parameters[\"output_classes\"]\n",
    "    \n",
    "    \n",
    "    #Layer 1\n",
    "    # CONV\n",
    "    Z1 = tf.nn.conv1d(X, CONV1_W, stride=CONV1_Str, padding='VALID', data_format='NWC', name='conv1')\n",
    "    # Batch Normalization\n",
    "    B1 = tf.contrib.layers.batch_norm(Z1, is_training=training)\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(B1)\n",
    "    \n",
    "    #Layer 2\n",
    "    # CONV\n",
    "    Z2 = tf.nn.conv1d(A1, CONV2_W, stride=CONV2_Str, padding='VALID', data_format='NWC', name='conv2')\n",
    "    # Batch Normalization\n",
    "    B2 = tf.contrib.layers.batch_norm(Z2, is_training=training)\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(B2)\n",
    "    \n",
    "    #Layer 3\n",
    "    # CONV\n",
    "    Z3 = tf.nn.conv1d(A2, CONV3_W, stride=CONV3_Str, padding='VALID', data_format='NWC', name='conv3')\n",
    "    # Batch Normalization\n",
    "    B3 = tf.contrib.layers.batch_norm(Z3, is_training=training)\n",
    "    # RELU\n",
    "    A3 = tf.nn.relu(B3)\n",
    "    \n",
    "    # Flatten activations for FC layer\n",
    "    A3_flat = tf.contrib.layers.flatten(A3)\n",
    "    \n",
    "    # Layer 4\n",
    "    # FC\n",
    "    A4 = tf.contrib.layers.fully_connected(A3_flat, FC1_units, activation_fn=tf.nn.relu)\n",
    "    # Dropout\n",
    "    A4_dropped = tf.contrib.layers.dropout(A4, keep_prob=DO_prob, is_training=training)\n",
    "    \n",
    "    # Layer 5\n",
    "    # FC\n",
    "    A5 = tf.contrib.layers.fully_connected(A4_dropped, output_classes, activation_fn=None)\n",
    "    \n",
    "    return A5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv1d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing cost function\n",
    "\n",
    "WRITE TEXT HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, Y, parameters, training):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply softmax to the output classes and find cross entropy loss\n",
    "    X - Input data\n",
    "    Y - One-hot output class training labels\n",
    "    \n",
    "    Returns:\n",
    "    cost - cross entropy loss\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_hat = forward_propagation(X, parameters, training=training)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Y_hat, labels=Y))\n",
    "    \n",
    "    return cost, Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites for training\n",
    "\n",
    "Here are some procedures that are necessary to execute before the actual training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create placeholders\n",
    "\n",
    "Tensorflow functions take input in the form of `feed_dict`. The variables in other functions are placeholders for the actual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates Tensorflow placeholders that act for input data and their labels\n",
    "    \n",
    "    Arguments:\n",
    "    n_x - no. of features for X\n",
    "    n_x - no. of classes for Y\n",
    "    \n",
    "    Returns:\n",
    "    X - placeholder for data that contains input featurs,\n",
    "        shape: (no. of examples, no. of features). No. of examples is set to None\n",
    "    Y - placeholder for data that contains output class labels,\n",
    "        shape (no. of examples, no. of classes). No. of examples is set ot None\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, name='X', shape=(None, n_x, 1))\n",
    "    Y = tf.placeholder(tf.float32, name='Y', shape=(None, n_y))\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    return X,Y,is_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter shapes\n",
    "\n",
    "To initialize model parameters, we've created a procedure above. It takes as an argument a dictionary in which we supply the model parameter shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_shapes():\n",
    "    \"\"\"\n",
    "    Get tha shapes of all parameters used in the model.\n",
    "    Convolutional layer parameter shapes (filters) are in list format\n",
    "    \n",
    "    Returns:\n",
    "    param_shapes - dict that contains all the parameters as follows\n",
    "    CONV1_W, CONV2_W, CONV3_W\n",
    "    param_values:\n",
    "    CONV1_Str, CONV2_Str, CONV3_Str,\n",
    "    FC1_units, DO_prob, output_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    param_shapes = {}\n",
    "    param_values = {}\n",
    "\n",
    "    # Conv Layer 1 parameter shapes\n",
    "    # No. of channels: 24, Filter size: 5, Stride: 3\n",
    "    param_shapes['CONV1_W'] = [5, 1, 24]\n",
    "    param_values['CONV1_Str'] = 3\n",
    "    \n",
    "    # Conv Layer 2 parameter shapes\n",
    "    # No. of channels: 16, Filter size: 3, Stride: 2\n",
    "    param_shapes['CONV2_W'] = [3, 24, 16]\n",
    "    param_values['CONV2_Str'] = 2\n",
    "    \n",
    "    # Conv Layer 3 parameter shapes\n",
    "    # No. of channels: 8, Filter size: 3, Stride: 2\n",
    "    param_shapes['CONV3_W'] = [3, 16, 8]\n",
    "    param_values['CONV3_Str'] = 2\n",
    "    \n",
    "    # Fully connected layer 1 units = 20\n",
    "    param_values['FC1_units'] = 20\n",
    "    \n",
    "    # Dropout layer after fully connected layer 1 probability\n",
    "    param_values['DO_prob'] = 0.5\n",
    "    \n",
    "    # Fully connected layer 2 units (also last layer)\n",
    "    # No. of units = no. of output classes = 3\n",
    "    param_values['output_classes'] = 3\n",
    "    \n",
    "    return param_shapes, param_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random mini-batches\n",
    "\n",
    "For each epoch we'll use different sets of mini-batches to avoid any possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (number of examples, window size) (m, n_x)\n",
    "    Y -- output classes, of shape (number of examples, output classes) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = np.floor(m/mini_batch_size).astype(int) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data\n",
    "\n",
    "WRITE TEXT HERE...\n",
    "\n",
    "[UPDATE_OPS](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs(costs, dev_costs, learning_rate):\n",
    "    # plot the cost\n",
    "    plt.plot(costs, color='blue', label='training')\n",
    "    plt.plot(dev_costs, color='green', label='dev')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    (m, n_x,_) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    dev_costs = []\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y, is_train = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    param_shapes, param_values = parameter_shapes()\n",
    "    parameters = initialize_parameters(param_shapes, param_values)\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    # Prediction: Use Y_hat to compute the output class during prediction\n",
    "    cost, Y_hat = compute_cost(X, Y, parameters, is_train)\n",
    "    \n",
    "    # For impementation of batch norm the tf.GraphKeys.UPDATE_OPS dependency needs to be added\n",
    "    # see documentation on tf.contrib.layers.batch_norm\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#     optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(Y_hat, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess, tf.control_dependencies(update_ops):\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        print(\"Cost at start: %f\" % cost.eval({X: X_train, Y: Y_train, is_train: False}))\n",
    "        print(\"Dev cost: %f\" % cost.eval({X: X_dev, Y: Y_dev, is_train: False}))\n",
    "        \n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Dev Accuracy:\", dev_accuracy)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    # Select a minibatch\n",
    "                    (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                    # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                    # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                    _,minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y, is_train: True})\n",
    "\n",
    "                    epoch_cost += minibatch_cost / num_minibatches\n",
    "                \n",
    "                # Implement early stopping mechanism on KeyboardInterrupt\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"KeyboardInterrupt received. Stopping early\")\n",
    "                    plot_costs(np.squeeze(costs), np.squeeze(dev_costs), learning_rate)\n",
    "                    return parameters\n",
    "                \n",
    "\n",
    "            # Save the costs after each epoch for plotting learning curve\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                dev_cost = cost.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "                dev_costs.append(dev_cost)\n",
    "                \n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and (epoch + 1) % 5 == 0:\n",
    "                print (\"\\nCost after epoch %i: %f\" % (epoch + 1, epoch_cost))\n",
    "                print (\"Dev cost after epoch %i: %f\" % (epoch + 1, dev_cost))\n",
    "                \n",
    "                train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "                dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "                print(\"Train Accuracy:\", train_accuracy)\n",
    "                print(\"Dev Accuracy:\", dev_accuracy)\n",
    "                \n",
    "                \n",
    "                \n",
    "        plot_costs(np.squeeze(costs), np.squeeze(dev_costs), learning_rate)\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "#         predict_op = tf.argmax(Y_hat, 1)\n",
    "#         correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "#         # Calculate accuracy on the test set\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train, is_train: False})\n",
    "        dev_accuracy = accuracy.eval({X: X_dev, Y: Y_dev, is_train: False})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Dev Accuracy:\", dev_accuracy)\n",
    "                \n",
    "        return parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at start: 1.102707\n",
      "Dev cost: 1.105215\n",
      "Train Accuracy: 0.38670567\n",
      "Dev Accuracy: 0.408\n",
      "\n",
      "Cost after epoch 5: 0.806574\n",
      "Dev cost after epoch 5: 1.062213\n",
      "Train Accuracy: 0.4633918\n",
      "Dev Accuracy: 0.46133333\n",
      "\n",
      "Cost after epoch 10: 0.615287\n",
      "Dev cost after epoch 10: 1.036935\n",
      "Train Accuracy: 0.4582846\n",
      "Dev Accuracy: 0.45866665\n",
      "\n",
      "Cost after epoch 15: 0.479126\n",
      "Dev cost after epoch 15: 1.023886\n",
      "Train Accuracy: 0.45754385\n",
      "Dev Accuracy: 0.464\n",
      "\n",
      "Cost after epoch 20: 0.431033\n",
      "Dev cost after epoch 20: 1.026809\n",
      "Train Accuracy: 0.4553996\n",
      "Dev Accuracy: 0.464\n",
      "\n",
      "Cost after epoch 25: 0.394382\n",
      "Dev cost after epoch 25: 1.039372\n",
      "Train Accuracy: 0.45212474\n",
      "Dev Accuracy: 0.46133333\n",
      "\n",
      "Cost after epoch 30: 0.369675\n",
      "Dev cost after epoch 30: 1.050577\n",
      "Train Accuracy: 0.43871346\n",
      "Dev Accuracy: 0.44533333\n",
      "\n",
      "Cost after epoch 35: 0.341556\n",
      "Dev cost after epoch 35: 1.058440\n",
      "Train Accuracy: 0.4348538\n",
      "Dev Accuracy: 0.44266668\n",
      "\n",
      "Cost after epoch 40: 0.323092\n",
      "Dev cost after epoch 40: 1.063277\n",
      "Train Accuracy: 0.42499027\n",
      "Dev Accuracy: 0.42133334\n",
      "\n",
      "Cost after epoch 45: 0.300200\n",
      "Dev cost after epoch 45: 1.064867\n",
      "Train Accuracy: 0.4274074\n",
      "Dev Accuracy: 0.424\n",
      "\n",
      "Cost after epoch 50: 0.287936\n",
      "Dev cost after epoch 50: 1.070747\n",
      "Train Accuracy: 0.4185185\n",
      "Dev Accuracy: 0.41333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4185185\n",
      "Dev Accuracy: 0.41333333\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_dev, Y_dev, learning_rate=0.00002, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>,\n",
       " 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>,\n",
       " 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>,\n",
       " 'CONV1_Str': 3,\n",
       " 'CONV2_Str': 2,\n",
       " 'CONV3_Str': 2,\n",
       " 'FC1_units': 20,\n",
       " 'DO_prob': 0.5,\n",
       " 'output_classes': 3}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'dict'> to Tensor. Contents: {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}. Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-0af0a1691af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"parameters-0.00002.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaver_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msave_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1279\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m   1280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1328\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    754\u001b[0m                        \" when eager execution is not enabled.\")\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    661\u001b[0m                            \u001b[0;31m# Avoid comparing ops, sort only by name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                            key=lambda x: x[0]):\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveableObjectsForOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddSaveable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_saveable_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaveables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mSaveableObjectsForOp\u001b[0;34m(op, name)\u001b[0m\n\u001b[1;32m    625\u001b[0m           \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_element\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m           \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IsVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m           raise TypeError(\"names_to_saveables must be a dict mapping string \"\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    215\u001b[0m                                          as_ref=False):\n\u001b[1;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    194\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    523\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    524\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'CONV1_W': <tf.Variable 'CONV1_W:0' shape=(5, 1, 24) dtype=float32_ref>, 'CONV2_W': <tf.Variable 'CONV2_W:0' shape=(3, 24, 16) dtype=float32_ref>, 'CONV3_W': <tf.Variable 'CONV3_W:0' shape=(3, 16, 8) dtype=float32_ref>, 'CONV1_Str': 3, 'CONV2_Str': 2, 'CONV3_Str': 2, 'FC1_units': 20, 'DO_prob': 0.5, 'output_classes': 3}. Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver({\"parameters\": parameters})\n",
    "save_filename = \"parameters-0.00002.ckpt\"\n",
    "with tf.Session() as saver_sess:\n",
    "    save_path = saver.save(saver_sess, \"train/\" + save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 0.1643085 ,  0.02832928,  0.00959623, -0.1577815 ,\n",
      "          0.18924351, -0.01189184, -0.01866665, -0.0223477 ,\n",
      "         -0.08435522,  0.14691184, -0.02915606,  0.11074157,\n",
      "          0.20260207,  0.20071696, -0.1872986 ,  0.12060685,\n",
      "         -0.01182598,  0.12479548,  0.15796684,  0.0713618 ,\n",
      "         -0.09553804,  0.09870629, -0.08830424, -0.02101901]],\n",
      "\n",
      "       [[-0.16887933,  0.16461147, -0.17514198,  0.0358382 ,\n",
      "          0.12785394, -0.0477768 , -0.09394044, -0.06481086,\n",
      "          0.20126636, -0.14165503,  0.09850214,  0.19882835,\n",
      "          0.19975846,  0.03520782, -0.0587478 , -0.07248875,\n",
      "          0.11210789,  0.17382033, -0.17019679, -0.13251658,\n",
      "         -0.05781738,  0.08353408,  0.15923844, -0.03437892]],\n",
      "\n",
      "       [[-0.01887622, -0.00399101, -0.03537577, -0.00912465,\n",
      "         -0.05754562,  0.13235386, -0.21564794, -0.09492114,\n",
      "          0.10254969,  0.11964042, -0.16168648, -0.10999942,\n",
      "          0.05496974,  0.01924798,  0.134133  ,  0.18148993,\n",
      "         -0.05380638,  0.0466698 ,  0.21100672,  0.11605178,\n",
      "         -0.15948132,  0.19808991,  0.03279395, -0.04511204]],\n",
      "\n",
      "       [[-0.1531505 ,  0.1360371 ,  0.17552187, -0.072657  ,\n",
      "          0.10390188,  0.2064978 , -0.2060738 , -0.00251307,\n",
      "          0.10316496,  0.1708117 , -0.18439575,  0.05672057,\n",
      "         -0.07450461,  0.15146177,  0.06291531, -0.15118815,\n",
      "         -0.01062907, -0.0947226 ,  0.00894162, -0.19388433,\n",
      "         -0.10948235, -0.01592223,  0.17893966, -0.02725476]],\n",
      "\n",
      "       [[-0.04409654,  0.1685492 , -0.11375062, -0.09052035,\n",
      "          0.14411877, -0.11179066, -0.04502575, -0.17790776,\n",
      "         -0.17113179,  0.16160111,  0.01867341, -0.10262924,\n",
      "         -0.18486305, -0.11137895,  0.20629053,  0.10506319,\n",
      "          0.04275133, -0.04294497, -0.1365886 , -0.08690064,\n",
      "         -0.05178347,  0.10505648,  0.09812795,  0.12511526]]],\n",
      "      dtype=float32), array([[[ 0.03454825, -0.07327656, -0.18433392, ...,  0.01384151,\n",
      "         -0.0376384 , -0.21241197],\n",
      "        [ 0.0264369 ,  0.09737429, -0.1662314 , ...,  0.01771265,\n",
      "          0.02779716,  0.2148824 ],\n",
      "        [ 0.09074643,  0.14955875,  0.10030431, ..., -0.17436606,\n",
      "          0.1132088 , -0.19364998],\n",
      "        ...,\n",
      "        [ 0.13966292,  0.09236509, -0.02404495, ..., -0.06317516,\n",
      "         -0.04378319,  0.17765734],\n",
      "        [-0.19157821,  0.15578228,  0.0189836 , ...,  0.0289264 ,\n",
      "         -0.11181726,  0.15346962],\n",
      "        [-0.15033194, -0.13815138, -0.06678775, ...,  0.20982501,\n",
      "         -0.08370359, -0.00093867]],\n",
      "\n",
      "       [[ 0.19088665, -0.02133679,  0.14586759, ...,  0.05037734,\n",
      "         -0.00991294,  0.19605312],\n",
      "        [ 0.04065531, -0.17088324, -0.00174026, ..., -0.14537781,\n",
      "          0.19790578,  0.12841159],\n",
      "        [ 0.03534409,  0.14828753,  0.08637324, ...,  0.1203579 ,\n",
      "         -0.02153736, -0.14773005],\n",
      "        ...,\n",
      "        [ 0.20435509,  0.12785128,  0.17734796, ...,  0.14683509,\n",
      "          0.07817471,  0.12274739],\n",
      "        [ 0.19478527, -0.08566473, -0.08895856, ..., -0.00590713,\n",
      "          0.05258766,  0.07641312],\n",
      "        [ 0.1245679 , -0.06362133,  0.01101671, ...,  0.08452523,\n",
      "          0.20335132,  0.0348587 ]],\n",
      "\n",
      "       [[-0.09215297,  0.00598225, -0.08681248, ..., -0.18807061,\n",
      "          0.10308492,  0.14881563],\n",
      "        [ 0.05426043,  0.05483988,  0.01513442, ...,  0.15597942,\n",
      "          0.18479496,  0.01043727],\n",
      "        [ 0.21021515, -0.07014853, -0.01030777, ...,  0.03580993,\n",
      "          0.13476515, -0.11279953],\n",
      "        ...,\n",
      "        [ 0.10904738, -0.04719312,  0.16810265, ...,  0.19397241,\n",
      "         -0.05813323, -0.21560493],\n",
      "        [ 0.12123638,  0.13133243, -0.05182946, ..., -0.02149242,\n",
      "         -0.16068082,  0.20637628],\n",
      "        [ 0.04394537, -0.11068022, -0.10675342, ..., -0.11137413,\n",
      "         -0.06647837,  0.01350191]]], dtype=float32), array([[[ 1.02950722e-01,  1.18730545e-01,  1.07318997e-01,\n",
      "         -8.23232234e-02,  7.22426176e-02,  2.65023172e-01,\n",
      "          6.90088570e-02, -2.83344179e-01],\n",
      "        [-2.46273652e-01,  1.98538214e-01,  2.46038437e-01,\n",
      "         -1.82627946e-01, -1.52395800e-01, -2.63979852e-01,\n",
      "         -2.27670670e-02, -1.25692457e-01],\n",
      "        [-3.07884812e-02, -3.99737954e-02, -5.51048666e-02,\n",
      "          6.06123507e-02, -2.14976013e-01, -2.05507413e-01,\n",
      "          5.10406494e-02, -9.43745077e-02],\n",
      "        [-2.23446503e-01, -1.58778533e-01,  3.96336615e-02,\n",
      "         -1.51973620e-01, -1.27636433e-01, -1.76890522e-01,\n",
      "         -2.90343761e-02,  2.11624682e-01],\n",
      "        [ 3.37957442e-02,  8.81038904e-02,  9.72135067e-02,\n",
      "         -5.28866202e-02, -9.40107703e-02,  1.39111698e-01,\n",
      "         -1.26710251e-01,  2.06310600e-01],\n",
      "        [-9.03185457e-02,  1.20239079e-01,  2.70825744e-01,\n",
      "          6.90641999e-02, -1.40377343e-01,  1.94017887e-01,\n",
      "          7.76210725e-02,  1.92006946e-01],\n",
      "        [ 2.60322213e-01, -1.86103567e-01, -4.73356396e-02,\n",
      "          1.31012946e-01,  5.36055863e-02, -1.49103254e-01,\n",
      "          9.57444906e-02,  2.63774395e-02],\n",
      "        [ 9.58490372e-03,  5.87722957e-02,  1.55969977e-01,\n",
      "          1.74715161e-01,  1.10131979e-01, -1.79722965e-01,\n",
      "         -2.02977732e-01, -8.39007050e-02],\n",
      "        [ 9.20522809e-02,  2.81835616e-01, -7.94733018e-02,\n",
      "          1.23090357e-01,  2.76783705e-01,  1.58143133e-01,\n",
      "          2.03613669e-01, -1.57769322e-02],\n",
      "        [ 2.83651412e-01,  2.36370862e-02,  1.26903713e-01,\n",
      "         -7.21476525e-02,  2.10845917e-01, -2.62569487e-01,\n",
      "          2.28163481e-01,  3.40013802e-02],\n",
      "        [-1.71139389e-01, -2.72915065e-02,  6.28378987e-02,\n",
      "         -1.44607767e-01,  1.30800962e-01, -1.05573595e-01,\n",
      "          8.13111663e-03, -2.88549602e-01],\n",
      "        [ 7.62977600e-02,  1.03350192e-01, -2.10062087e-01,\n",
      "         -3.14284861e-02, -6.53753579e-02,  2.84851491e-02,\n",
      "          2.82338381e-01,  7.89079070e-02],\n",
      "        [ 1.15689635e-03, -2.51100361e-02,  2.55950332e-01,\n",
      "         -4.99835014e-02, -1.34336799e-01,  1.70196891e-01,\n",
      "         -2.52049506e-01,  2.71742284e-01],\n",
      "        [-1.89778984e-01, -2.40322724e-01,  2.45203614e-01,\n",
      "          2.04512477e-01, -1.79761365e-01,  1.92244381e-01,\n",
      "          1.49027675e-01, -1.68645769e-01],\n",
      "        [ 1.34132117e-01, -7.20069110e-02,  2.34913051e-01,\n",
      "         -1.96531266e-01,  1.61745042e-01, -1.94820046e-01,\n",
      "         -2.87820458e-01, -1.67443871e-01],\n",
      "        [ 6.68334961e-02,  7.14491308e-02,  9.42706466e-02,\n",
      "         -1.34689599e-01, -1.26563907e-02,  1.37816548e-01,\n",
      "          1.63856953e-01, -2.61959344e-01]],\n",
      "\n",
      "       [[ 2.17077672e-01,  1.87536240e-01,  5.84517121e-02,\n",
      "         -2.43552357e-01,  2.30777860e-01,  9.85579193e-02,\n",
      "         -1.34772271e-01,  4.11887765e-02],\n",
      "        [ 2.51484394e-01,  1.86256856e-01, -1.41883999e-01,\n",
      "          1.99499488e-01,  2.79091716e-01, -1.80168197e-01,\n",
      "          5.14957309e-02,  4.73426580e-02],\n",
      "        [-2.05032229e-01,  9.48527753e-02,  2.10830569e-02,\n",
      "         -1.31457359e-01, -5.30168414e-02, -6.81270659e-02,\n",
      "         -9.00667906e-02, -1.09920129e-01],\n",
      "        [ 9.95755792e-02, -9.47534591e-02, -1.63414761e-01,\n",
      "          8.57711136e-02,  1.30634397e-01,  1.21790111e-01,\n",
      "          2.78981864e-01, -1.73031539e-01],\n",
      "        [-8.05658400e-02,  1.26271486e-01,  2.20297575e-01,\n",
      "          1.56350374e-01, -1.73342705e-01,  1.50721192e-01,\n",
      "          2.54926443e-01, -2.31285319e-01],\n",
      "        [-5.49211055e-02,  9.10106301e-03,  4.38214242e-02,\n",
      "         -1.10613406e-01,  4.25764918e-02,  2.07217723e-01,\n",
      "          2.76342630e-02, -5.85610867e-02],\n",
      "        [-2.42733061e-02, -2.42362648e-01,  1.22362822e-01,\n",
      "          3.44445407e-02, -2.81431586e-01,  1.96363539e-01,\n",
      "          1.10555053e-01,  6.84531629e-02],\n",
      "        [ 1.63581878e-01,  2.07843691e-01,  9.27260816e-02,\n",
      "          5.88607490e-02, -1.15785301e-02, -2.88280547e-01,\n",
      "         -2.89491713e-02, -1.78664923e-04],\n",
      "        [ 1.41320199e-01, -1.34216428e-01, -4.75118309e-02,\n",
      "         -1.08882859e-01, -8.35332572e-02,  3.06995511e-02,\n",
      "          9.61816013e-02,  2.74289191e-01],\n",
      "        [-7.31465220e-03, -2.42105514e-01, -5.83755970e-03,\n",
      "          1.29757524e-02,  6.21838570e-02, -1.81705967e-01,\n",
      "         -3.61042917e-02,  2.52677202e-01],\n",
      "        [ 4.78157401e-03,  2.73520827e-01, -3.65942717e-04,\n",
      "          2.75783360e-01,  1.60678655e-01,  2.00209141e-01,\n",
      "         -9.93467420e-02,  5.61647713e-02],\n",
      "        [ 2.44768381e-01, -7.13432878e-02, -1.99440375e-01,\n",
      "         -8.72054696e-03, -5.34320623e-02, -2.78233290e-02,\n",
      "         -3.43827605e-02,  2.66410947e-01],\n",
      "        [-2.09450692e-01,  2.73653150e-01, -6.39496446e-02,\n",
      "         -8.29343945e-02,  1.84497237e-02,  8.89908969e-02,\n",
      "         -4.20951992e-02,  6.57205284e-02],\n",
      "        [ 1.27949923e-01, -1.61904514e-01,  1.06198609e-01,\n",
      "         -9.87475514e-02, -2.32993156e-01,  9.74774361e-02,\n",
      "         -2.19867304e-01, -1.29379854e-01],\n",
      "        [ 2.37938762e-02,  2.34745800e-01,  1.10285521e-01,\n",
      "         -2.70861149e-01, -2.83558518e-01, -1.96012110e-01,\n",
      "         -8.67789984e-02, -2.69347131e-02],\n",
      "        [-2.64090300e-01, -2.61319041e-01,  1.12095773e-01,\n",
      "          1.16068870e-01,  4.22601700e-02,  2.73968041e-01,\n",
      "         -4.94633764e-02, -2.16769055e-01]],\n",
      "\n",
      "       [[ 1.72984064e-01,  4.06078100e-02, -2.84014463e-01,\n",
      "         -2.15610594e-01, -2.66804099e-02,  2.12236464e-01,\n",
      "          2.35042572e-01,  9.04244184e-03],\n",
      "        [ 2.54772961e-01,  1.31989360e-01, -1.47773057e-01,\n",
      "          2.10858256e-01,  1.32705301e-01,  2.31767893e-02,\n",
      "          9.35549438e-02, -1.25227064e-01],\n",
      "        [-1.14757717e-02,  2.29272425e-01, -1.97507545e-01,\n",
      "         -2.74226576e-01,  1.32009953e-01, -1.23115152e-01,\n",
      "          1.67219907e-01,  2.51698434e-01],\n",
      "        [ 2.76752472e-01,  3.91109288e-02, -1.66488290e-02,\n",
      "          1.40302807e-01, -1.02879271e-01,  2.55242646e-01,\n",
      "         -1.76653415e-01, -5.16962856e-02],\n",
      "        [-7.53324181e-02, -3.12095881e-03,  2.09848374e-01,\n",
      "         -1.00263909e-01,  2.10619867e-02, -8.64804238e-02,\n",
      "         -9.16178375e-02,  7.63621032e-02],\n",
      "        [-3.80457938e-02, -2.65606046e-02,  5.98763525e-02,\n",
      "         -2.15495855e-01, -1.14389926e-01, -1.65411651e-01,\n",
      "          1.17951781e-01, -7.62358159e-02],\n",
      "        [ 1.41508698e-01, -2.31706798e-01, -1.71919167e-02,\n",
      "         -2.72764951e-01, -2.17244923e-01,  2.65020907e-01,\n",
      "          1.50473624e-01, -2.48908103e-02],\n",
      "        [ 7.66454637e-02, -1.13805190e-01,  2.72380292e-01,\n",
      "          1.82288170e-01, -3.45466137e-02, -1.99644864e-02,\n",
      "          7.46965408e-02,  1.13599598e-01],\n",
      "        [-2.87346184e-01,  1.38681561e-01, -1.76061869e-01,\n",
      "          6.47832453e-02, -1.17661282e-01, -1.52566269e-01,\n",
      "          3.70444357e-02,  1.03836298e-01],\n",
      "        [ 1.92352116e-01, -3.70763838e-02, -1.04354352e-01,\n",
      "          1.13566160e-01,  1.17064297e-01, -1.03444204e-01,\n",
      "          1.95107818e-01,  3.01044285e-02],\n",
      "        [-1.92425668e-01, -1.18113533e-01,  2.69835711e-01,\n",
      "          1.52462333e-01,  1.79591924e-01, -1.90701321e-01,\n",
      "         -2.15742856e-01,  1.75316900e-01],\n",
      "        [ 2.52963781e-01, -4.10325974e-02,  5.41266501e-02,\n",
      "          2.33979821e-01, -2.72689849e-01, -2.64694333e-01,\n",
      "         -1.47999018e-01,  3.24014127e-02],\n",
      "        [-8.56428891e-02,  2.21977651e-01,  7.31682777e-02,\n",
      "         -1.12265363e-01,  2.92432606e-02, -7.43502825e-02,\n",
      "         -1.02957532e-01, -1.59043863e-01],\n",
      "        [ 7.78135061e-02,  2.10855901e-02,  3.23891640e-03,\n",
      "         -2.91174650e-03,  2.83964038e-01,  2.64204383e-01,\n",
      "         -2.17408240e-02,  1.18493915e-01],\n",
      "        [-5.22500575e-02, -5.08023202e-02,  9.91666913e-02,\n",
      "          2.54862368e-01, -1.21082246e-01,  2.49309182e-01,\n",
      "         -2.51968831e-01,  2.13175237e-01],\n",
      "        [-3.27252150e-02,  2.44670153e-01,  2.23190606e-01,\n",
      "          2.18800962e-01,  2.16511488e-01,  1.55409276e-02,\n",
      "          5.58165908e-02, -1.93617180e-01]]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 0.0938587 , -0.07239331, -0.06818514, ...,  0.02098723,\n",
      "         0.04155301,  0.05539155],\n",
      "       [-0.01821527, -0.08697401, -0.11177664, ..., -0.10056333,\n",
      "         0.082904  , -0.02161622],\n",
      "       [-0.11454282,  0.11155944, -0.12167596, ...,  0.01112506,\n",
      "         0.00296307, -0.0262356 ],\n",
      "       ...,\n",
      "       [-0.00430894,  0.0572931 , -0.09514384, ..., -0.06464636,\n",
      "         0.1161419 ,  0.04919173],\n",
      "       [ 0.1122954 , -0.00684194, -0.02432487, ..., -0.08732492,\n",
      "         0.10387705,  0.04345487],\n",
      "       [-0.08378898, -0.01144139, -0.05281067, ..., -0.11202651,\n",
      "        -0.0297015 , -0.08832225]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), array([[ 0.17008138, -0.29384038, -0.17582312],\n",
      "       [ 0.00385129,  0.23175842, -0.04472902],\n",
      "       [-0.21134475, -0.20951521,  0.00133795],\n",
      "       [ 0.16000634, -0.32329294, -0.09981862],\n",
      "       [ 0.23417515,  0.48110473,  0.27441633],\n",
      "       [ 0.30358166, -0.34617826, -0.04411149],\n",
      "       [-0.19648099,  0.03667688,  0.02367514],\n",
      "       [ 0.22302496,  0.2957548 ,  0.42723453],\n",
      "       [-0.00428814, -0.4516687 ,  0.39783603],\n",
      "       [ 0.22385854,  0.01701647,  0.18520135],\n",
      "       [ 0.11497879, -0.44391164,  0.27624393],\n",
      "       [-0.04469064, -0.16853267, -0.25371757],\n",
      "       [-0.3041938 ,  0.30201828, -0.22988763],\n",
      "       [ 0.48649782,  0.43864554,  0.4829765 ],\n",
      "       [ 0.2568043 ,  0.28930557,  0.15248835],\n",
      "       [ 0.03378099,  0.03613704,  0.38515252],\n",
      "       [ 0.23071128,  0.06223392,  0.36065465],\n",
      "       [-0.11145878, -0.19355574,  0.4271729 ],\n",
      "       [ 0.22493279,  0.20551085,  0.19637382],\n",
      "       [ 0.3531229 , -0.3203163 , -0.5090971 ]], dtype=float32), array([0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 3.95124257e-02, -1.14047468e-01,  9.16563272e-02, ...,\n",
      "         9.97388959e-02,  1.15336046e-01,  4.57376689e-02],\n",
      "       [-4.13841084e-02, -8.42704922e-02, -6.64013997e-02, ...,\n",
      "        -7.04465285e-02,  8.28883052e-02, -5.17144799e-04],\n",
      "       [-7.39231706e-02, -1.72678009e-02, -3.12894583e-02, ...,\n",
      "         1.40619874e-02,  8.43380392e-03, -9.59861577e-02],\n",
      "       ...,\n",
      "       [ 9.15815383e-02, -8.19035172e-02, -9.41449031e-02, ...,\n",
      "         2.42517740e-02,  1.03577465e-01,  2.04876661e-02],\n",
      "       [-7.72297010e-02, -1.04477726e-01,  3.24738175e-02, ...,\n",
      "        -5.34086078e-02,  3.88605893e-03,  1.00998834e-01],\n",
      "       [-3.24654952e-02,  3.49085480e-02, -1.13127008e-01, ...,\n",
      "         1.20908409e-01, -1.07735395e-05,  9.57140177e-02]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32), array([[-0.29862058, -0.44624907,  0.21366   ],\n",
      "       [ 0.26665425,  0.13070041,  0.20315486],\n",
      "       [-0.37168783,  0.02024859,  0.44429207],\n",
      "       [-0.39684933,  0.2000565 , -0.17609468],\n",
      "       [-0.05052942,  0.47739136, -0.2529828 ],\n",
      "       [-0.03275603,  0.28452605,  0.37867087],\n",
      "       [ 0.48413622, -0.2487379 ,  0.2599476 ],\n",
      "       [ 0.08251607,  0.26540947,  0.503105  ],\n",
      "       [-0.08899528,  0.47121477,  0.02866066],\n",
      "       [-0.07428119, -0.4686378 ,  0.40427893],\n",
      "       [-0.03408322,  0.5034773 , -0.46455207],\n",
      "       [ 0.46196437,  0.5001771 ,  0.14000452],\n",
      "       [ 0.2928999 ,  0.35588312,  0.24679661],\n",
      "       [ 0.33063585, -0.44646436,  0.15195471],\n",
      "       [-0.06311822,  0.04519856, -0.0905686 ],\n",
      "       [-0.08188018,  0.47788906, -0.28416136],\n",
      "       [-0.18828857, -0.30228755, -0.06532854],\n",
      "       [ 0.15629607,  0.4906674 , -0.3866003 ],\n",
      "       [ 0.08491296,  0.15673262,  0.27497488],\n",
      "       [-0.32988864,  0.46208346, -0.08739921]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(train_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
